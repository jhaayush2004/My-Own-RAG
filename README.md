
# My Own RAG System
No use of any frameworks like Llama_index, Langchain, etc.
## What is RAG ?

Retrieval-augmented generation (RAG) is a framework in generative AI (GenAI) that combines the capabilities of large language models (LLMs) with traditional information retrieval systems. RAG allows LLMs to access and use up-to-date and trustworthy information from internal knowledge bases without needing to be retrained. 
![App Screenshot](https://github.com/jhaayush2004/My-Own-RAG/blob/main/visuals/RAG.png)
## About my work
### 1. Setting up the toolbox: 
 Discovered the essential Python libraries we need to build  RAG pipeline.

### 2. Building the retrieval component:  
Learnt how to embed and store our documents, and perform similarity search using cosine similarity.
![App Screenshot](https://github.com/jhaayush2004/My-Own-RAG/blob/main/visuals/cosine.png)
### 3. Crafting the prompt builder: 
Explored strategies for constructing informative prompts that guide the large language model (LLM).

### 4. Integrating the LLM: 
Learn how to connect our RAG pipeline with an LLM of our choice, here we used Ollama gemma:7B.

### 5. Putting it all together: 
Witnessed the magic unfold as we combine these components into a seamless RAG pipeline.

### 6. Testing and exploring: 
Experimented with different prompts and observed how they influence the generated text.
